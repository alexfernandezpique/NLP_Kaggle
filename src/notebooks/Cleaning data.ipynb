{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType, FloatType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class py_or_udf:\n",
    "    def __init__(self, returnType=StringType()):\n",
    "        self.spark_udf_type = returnType\n",
    "        \n",
    "    def __call__(self, func):\n",
    "        def wrapped_func(*args, **kwargs):\n",
    "            if any([isinstance(arg, F.Column) for arg in args]) or \\\n",
    "                any([isinstance(vv, F.Column) for vv in kwargs.values()]):\n",
    "                return F.udf(func, self.spark_udf_type)(*args, **kwargs)\n",
    "            else:\n",
    "                return func(*args, **kwargs)\n",
    "            \n",
    "        return wrapped_func\n",
    "\n",
    "def format_name(author):\n",
    "    middle_name = \" \".join(author['middle'])\n",
    "    \n",
    "    if author['middle']:\n",
    "        return \" \".join([author['first'], middle_name, author['last']])\n",
    "    else:\n",
    "        return \" \".join([author['first'], author['last']])\n",
    "\n",
    "def format_affiliation(affiliation):\n",
    "    text = []\n",
    "    location = affiliation.get('location')\n",
    "    if location:\n",
    "        text.extend(list(affiliation['location'].values()))\n",
    "    \n",
    "    institution = affiliation.get('institution')\n",
    "    if institution:\n",
    "        text = [institution] + text\n",
    "    return \", \".join(text)\n",
    "\n",
    "@py_or_udf()\n",
    "def format_authors(authors, with_affiliation=False):\n",
    "    name_ls = []\n",
    "    \n",
    "    for author in authors:\n",
    "        name = format_name(author)\n",
    "        if with_affiliation:\n",
    "            affiliation = format_affiliation(author['affiliation'])\n",
    "            if affiliation:\n",
    "                name_ls.append(f\"{name} ({affiliation})\")\n",
    "            else:\n",
    "                name_ls.append(name)\n",
    "        else:\n",
    "            name_ls.append(name)\n",
    "    \n",
    "    return \", \".join(name_ls)\n",
    "\n",
    "@py_or_udf()\n",
    "def format_body(body_text):\n",
    "    texts = [(di['section'], di['text']) for di in body_text]\n",
    "    texts_di = {di['section']: \"\" for di in body_text}\n",
    "    \n",
    "    for section, text in texts:\n",
    "        texts_di[section] += text\n",
    "\n",
    "    body = \"\"\n",
    "\n",
    "    for section, text in texts_di.items():\n",
    "        body += section\n",
    "        body += \"\\n\\n\"\n",
    "        body += text\n",
    "        body += \"\\n\\n\"\n",
    "    \n",
    "    return body\n",
    "\n",
    "@py_or_udf()\n",
    "def format_bib(bibs):\n",
    "    if type(bibs) == dict:\n",
    "        bibs = list(bibs.values())\n",
    "    formatted = []\n",
    "    for bib in bibs:\n",
    "        title_str = str(bib['title'])\n",
    "        authors_str = format_authors(bib['authors'], False)\n",
    "        formatted_ls = [title_str, authors_str] + [str(bib[k]) for k in ['venue', 'year']]\n",
    "        formatted.append(\", \".join(formatted_ls))\n",
    "\n",
    "    return \"; \".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path_bio = \"/data/biorxiv_medrxiv/biorxiv_medrxiv/\"\n",
    "list_files = os.listdir(files_path_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = spark.read.option(\"multiline\",True).json(files_path_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_processed = (input_files.withColumn('body_text', format_body(F.col('body_text')))\n",
    "                                    .withColumn('abstract', format_body(F.col('abstract')))\n",
    "                                    .withColumn('title', F.col('metadata.title'))\n",
    "                                    .withColumn('authors', format_authors(F.col('metadata.authors')))\n",
    "                                    #.withColumn('bib_entries', format_bib(F.col('bib_entries')))\n",
    "                                    .drop('back_matter','metadata','ref_entries', 'bib_entries'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_processed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_processed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}